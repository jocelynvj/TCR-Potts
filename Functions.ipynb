{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eba6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import sample, randrange\n",
    "from collections import Counter,defaultdict\n",
    "from statistics import mean\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm,style\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold, cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report,roc_curve, roc_auc_score, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import scipy.cluster.hierarchy as hc\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "from scipy.spatial.distance import squareform,pdist\n",
    "\n",
    "import pyrepseq as rs\n",
    "import pyrepseq.plotting as rsp\n",
    "import pyrepseq.distance as rsd\n",
    "import pyrepseq.stats as rss\n",
    "\n",
    "from Levenshtein import hamming as hamming_distance\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df54535",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09efbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbours(x_train, y_train, x_test, k, distance_metric = levenshtein_distance):\n",
    "    '''\n",
    "    Calculates a list of the k-nearest neighbours\n",
    "    of a test sequence based on a distance metric (default = Levenshtein)\n",
    "    Inputs:\n",
    "        - x_train: training sequences\n",
    "        - y_train: epitopes corresponding to sequences\n",
    "        - x_test: testing sequence\n",
    "        - k: number of neighbours\n",
    "    Returns:\n",
    "        - list of k 3-tuples  (sequence, distance, epitope)\n",
    "    '''\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "        dist = distance_metric(x_test, x_train[i]) # calculate distance\n",
    "        distances.append((x_train[i], dist, y_train[i]))\n",
    "        \n",
    "    distances.sort(key=lambda x: x[1]) # sort by ascending distance\n",
    "    \n",
    "    neighbours = distances[:k] #k-nearest sequences\n",
    "    return neighbours\n",
    "\n",
    "def majority_vote(neighbours):\n",
    "    '''\n",
    "    Finds the majority class of k-nearest neighbours\n",
    "    Input:\n",
    "        - neighbours: list of k 3-tuples (sequence, distance, epitope)\n",
    "    Returns:\n",
    "        - maj: majority class\n",
    "        - maj_prob: probability of majority class\n",
    "    '''\n",
    "    class_counter = Counter()\n",
    "    number_of_neighbours = len(neighbours)\n",
    "    \n",
    "    for i in range(number_of_neighbours):\n",
    "        dist, label = neighbours[i][1], neighbours[i][2]\n",
    "\n",
    "        #class_counter[label] += 1 / (dist**2 + 1) #weighted\n",
    "        class_counter[label] += 1 # frequency of each epitope in k-neighbours(unweighted)\n",
    "\n",
    "    epitopes, votes = zip(*class_counter.most_common()) \n",
    "    \n",
    "    # find majority epitope and probability \n",
    "    maj = class_counter.most_common(1)[0][0] \n",
    "    maj_votes = class_counter.most_common(1)[0][1]\n",
    "    maj_prob = (maj_votes / sum(votes))\n",
    "    \n",
    "    return maj, maj_prob\n",
    "\n",
    "def KNN(x_train, x_test, y_train, y_test, k = 9, \n",
    "        distance_metric=levenshtein_distance):\n",
    "    '''\n",
    "    Predicts the epitopes of x_test based on K-NN and\n",
    "    finds the accuracy from y_test\n",
    "    Inputs:\n",
    "        - x_train, x_test, y_train, y_test: training and testing sequences and epitopes\n",
    "        - k: number of nearest neighbours\n",
    "        - distance_metric: distance metric to find K-NN\n",
    "    Returns:\n",
    "        - accuracy: fraction of epitopes correctly\n",
    "        predicted by K-NN classifier \n",
    "        - y_pred: predicted epitopes\n",
    "    \n",
    "    '''\n",
    "    y_pred =[]\n",
    "    for i, test_seq in enumerate(x_test):\n",
    "        neighbours = find_neighbours(x_train, y_train,test_seq, k,distance_metric) # find nearenst neighbours\n",
    "        predicted_epi, prob_pred = majority_vote(neighbours) # find majority neighbouring epitope and probability\n",
    "        y_pred.append(predicted_epi)\n",
    "        \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return(accuracy,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4ce882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, test_rat = 0.2):\n",
    "    '''\n",
    "    Splits data in k folds.\n",
    "    Inputs:\n",
    "        - dataset\n",
    "        - folds: number of folds\n",
    "    Returns:\n",
    "        - k arrays of the split dataset  \n",
    "    '''\n",
    "    dataset_split = []\n",
    "    df_copy = dataset\n",
    "    n_folds = int(1/test_rat)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "        \n",
    "    # for loop to save each fold\n",
    "    for i in range(n_folds):\n",
    "        fold = []\n",
    "\n",
    "        while len(fold) < fold_size:\n",
    "            index = df_copy.index[randrange(len(df_copy))] # index of a random element\n",
    "            fold.append(df_copy.loc[index].values.tolist()) # save the randomly selected line\n",
    "            df_copy = df_copy.drop(index) # delete selected line to avoid re-selection\n",
    "\n",
    "        dataset_split.append(np.asarray(fold)) # save the i-th fold   \n",
    "\n",
    "        \n",
    "    return dataset_split \n",
    "\n",
    "def kfoldCV(dataset, k, test_rat = 0.2):\n",
    "    '''\n",
    "    Find cross-validated accuracy of K-NN classifier\n",
    "    Inputs:\n",
    "        - dataset\n",
    "        - folds: number of folds\n",
    "        - k: number of neighbours\n",
    "    Returns:\n",
    "        - kfold_acc: accuracies from each fold\n",
    "        - mean_acc: mean accuracy between all folds\n",
    "    '''\n",
    "    split_data=cross_validation_split(dataset, test_rat = 0.2)\n",
    "    n_folds = int(1/test_rat)\n",
    "    kfold_acc=[]\n",
    "    \n",
    "    # evaluate K-NN performance for each fold\n",
    "    for i in range(n_folds):\n",
    "        r = list(range(n_folds))\n",
    "        r.pop(i) # removes i-th group\n",
    "        for j in r :\n",
    "            if j == r[0]:\n",
    "                cv_train = split_data[j]\n",
    "            else:    \n",
    "                cv_train=np.concatenate((cv_train,split_data[j]), axis=0)\n",
    "                \n",
    "        # determine training and test sets\n",
    "        x_train, y_train = cv_train[:,0:1],cv_train[:,1]\n",
    "        x_test, y_test= split_data[i][:,0:1], split_data[0][:,1]\n",
    "\n",
    "        accuracy, y_predictions = KNN(x_train, x_test, y_train,y_test ,k) # assess KNN performance on this fold\n",
    "        kfold_acc.append(accuracy)\n",
    "        \n",
    "    mean_acc  = mean(kfold_acc) # average accuracy between all k-folds\n",
    "        \n",
    "    return kfold_acc, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0fe53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_KNN_accs(two_seqs, test_neighbours_no, cv_show = False, n_iter = 1, \n",
    "                  test_rat = 0.2, rand_state = 1):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(two_seqs['CDR3'], two_seqs['Epitope'], test_size = test_rat, random_state = rand_state)\n",
    "    x_train = x_train.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    x_test = x_test.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "    \n",
    "    n_folds = int(1/test_rat)\n",
    "    cv_dataset = (two_seqs.drop(columns=['Chain Length']))\n",
    "    \n",
    "    knn_tts_accs =[]\n",
    "    cv_accs=[]\n",
    "\n",
    "\n",
    "    for k in test_neighbours_no:\n",
    "\n",
    "        train_test_split_acc, y_predictions = KNN(x_train, x_test, y_train, y_test,k)\n",
    "        knn_tts_accs.append(train_test_split_acc)\n",
    "        \n",
    "        print(f\"k={k} \\t\\t train_test_split accuracy = {train_test_split_acc:.6f}\")\n",
    "        \n",
    "        if cv_show:\n",
    "            kfold_acc, cv_acc = kfoldCV(cv_dataset, k=k)\n",
    "            cv_accs.append(cv_acc)\n",
    "            print(f\"CV accuracy = {cv_acc:.6f}\")\n",
    "\n",
    "    ep = two_seqs.value_counts('Epitope')\n",
    "    epi = ', '.join(ep.index.tolist())\n",
    "    random_accuracy = 1/ep.size\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.title(f\"K-NN Classifier for {epi} epitopes\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(test_neighbours_no,knn_tts_accs,'.-',label='train test split', linewidth=1.2)\n",
    "    plt.axhline(y = random_accuracy, color = 'r', linestyle = '--',label = 'random classifier', alpha = 0.4)\n",
    "    if cv_show:\n",
    "        plt.plot(test_neighbours_no,cv_accs,'.-',label='cross-validation',linewidth=1.2)\n",
    "    plt.legend()    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ad18b",
   "metadata": {},
   "source": [
    "## Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991bd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_align(sequences,showmaxlength=True, set_maxlength = 25, global_maxlength = 19, include_local = False): \n",
    "    \n",
    "    oldmaxlength = sequences['Chain Length'].max()\n",
    "    if oldmaxlength>set_maxlength:\n",
    "        new_seqs = sequences.drop(sequences[sequences['Chain Length'] > set_maxlength].index, inplace = False)\n",
    "    else:\n",
    "        new_seqs = sequences\n",
    "\n",
    "    newmaxlength = new_seqs['Chain Length'].max()\n",
    "        \n",
    "    if showmaxlength:\n",
    "        print(f\"Old max. length = {oldmaxlength}, new local max. length = {newmaxlength}.\")\n",
    "        \n",
    "    if include_local: l_aligned, r_aligned = [],[]\n",
    "    \n",
    "    l_aligned_glob, r_aligned_glob = [],[]\n",
    "    \n",
    "    for seq in new_seqs['CDR3']:\n",
    "        length = len(seq)\n",
    "        \n",
    "        if include_local: \n",
    "            lseq,rseq = seq,seq\n",
    "            while length < newmaxlength:\n",
    "                lseq,rseq  = lseq+'-', '-'+rseq\n",
    "                length +=1\n",
    "            l_aligned.append(lseq)\n",
    "            r_aligned.append(rseq)\n",
    "            \n",
    "            \n",
    "        lseq_glob,rseq_glob = seq,seq\n",
    "        while length < global_maxlength:\n",
    "                lseq_glob,rseq_glob  = lseq_glob+'-', '-'+rseq_glob\n",
    "                length +=1\n",
    "        l_aligned_glob.append(lseq_glob)\n",
    "        r_aligned_glob.append(rseq_glob)\n",
    "    \n",
    "    \n",
    "    d = {'Epitope':new_seqs['Epitope'],\n",
    "         'Old length':new_seqs['Chain Length'],\n",
    " \n",
    "         'Glob lalg': l_aligned_glob, \n",
    "         'Glob ralg': r_aligned_glob,\n",
    "         'Glob alg length': global_maxlength\n",
    "        }\n",
    "    if include_local: \n",
    "        d['Loc lalg'] = l_aligned\n",
    "        d['Loc ralg'] = r_aligned\n",
    "        d['Loc alg length'] = newmaxlength\n",
    "        \n",
    "            \n",
    "    df = pd.DataFrame(data=d)\n",
    "    #return(l_aligned, r_aligned, new_seqs['Epitope'].to_numpy() )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83652fd",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e29255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_clustermap(df, dist_thres=6,epitope_name = 'epitope', alpha_column='cdr3a', beta_column='cdr3b',\n",
    "                          norm=None,\n",
    "                          linkage_kws=dict(method='average', optimal_ordering=True),\n",
    "                          #cluster_kws=dict(t=6, criterion='distance'),\n",
    "                          cbar_kws=dict(label='Sequence Distance',\n",
    "                              format='%d', orientation='horizontal'),\n",
    "                          meta_columns=None,\n",
    "                          meta_to_colors=None,\n",
    "                          **kws):\n",
    "    \"\"\"\n",
    "    Plots a sequence-similarity clustermap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame with data\n",
    "    alpha_column, beta_column: column name with alpha and beta amino acid information\n",
    "    norm: function to normalize distances\n",
    "    linkage_kws: keyword arguments for linkage algorithm\n",
    "    cluster_kws: keyword arguments for clustering algorithm\n",
    "    cbar_kws: keyword arguments for colorbar\n",
    "    meta_columns: list-like\n",
    "        metadata to plot alongside the cluster assignment \n",
    "    meta_to_colors: list-like\n",
    "        list of functions mapping metadata labels to colors\n",
    "        first element of list is for clusters\n",
    "    kws: keyword arguments passed on to the clustermap.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Distance threshold: \",dist_thres)\n",
    "    if meta_to_colors is None:\n",
    "        if meta_columns is None:\n",
    "            meta_to_colors = [rsp.labels_to_colors_hls]\n",
    "        else:\n",
    "            meta_to_colors = [rsp.labels_to_colors_hls]*(len(meta_columns)+1)\n",
    "\n",
    "    sequences_alpha = df[alpha_column]\n",
    "    sequences_beta = df[beta_column]\n",
    "    sequences = sequences_alpha + '_' + sequences_beta\n",
    "\n",
    "    distances_alpha = rsd.pdist(sequences_alpha)\n",
    "    distances_beta = rsd.pdist(sequences_beta)\n",
    "    distances = distances_alpha + distances_beta\n",
    "    linkage = hc.linkage(distances, **linkage_kws)\n",
    "    cluster = hc.fcluster(linkage, **dict(t=dist_thres, criterion='distance'))\n",
    "\n",
    "    cmap = plt.cm.viridis\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "        'Custom cmap', list(reversed(cmaplist)), cmap.N)\n",
    "\n",
    "    if norm is None:\n",
    "        bounds = np.arange(0, dist_thres+1, 1) \n",
    "        norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "        # plot tick in the middle of the discretized colormap\n",
    "        cbar_kws.update(dict(ticks=bounds[:-1]+0.5))\n",
    "\n",
    "    cluster_colors = pd.Series(meta_to_colors[0](cluster, min_count=2),\n",
    "                               name='Cluster')\n",
    "    if not meta_columns is None:\n",
    "        colors_list = [cluster_colors]\n",
    "        if type(meta_columns) is dict:\n",
    "            meta_colors = [pd.Series(mapper(df[col]), name=meta_columns[col])\n",
    "                    for col, mapper in zip(meta_columns, meta_to_colors[1:])]\n",
    "        else:\n",
    "            meta_colors = [pd.Series(mapper(df[col]), name=col)\n",
    "                    for col, mapper in zip(meta_columns, meta_to_colors[1:])]\n",
    "        colors_list.extend(meta_colors)\n",
    "        colors = pd.concat(colors_list, axis=1)\n",
    "    else:\n",
    "        colors = cluster_colors\n",
    "    \n",
    "    \n",
    "    # default clustermap kws\n",
    "    clustermap_kws = dict(cbar_kws=cbar_kws,\n",
    "                          dendrogram_ratio=0.12, colors_ratio=0.04,\n",
    "                          cbar_pos=(0.38, .99, .4, .02),\n",
    "                          rasterized=True, figsize=(4.2, 4.2),\n",
    "                          xticklabels=[], yticklabels=[],\n",
    "                          )\n",
    "    clustermap_kws.update(kws)\n",
    "    \n",
    "    cg = rsp.clustermap_split(pd.DataFrame(squareform(distances_alpha)),\n",
    "                          pd.DataFrame(squareform(distances_beta)),\n",
    "                          row_linkage=linkage, col_linkage=linkage,\n",
    "                          cmap=cmap, norm=norm,\n",
    "                          row_colors=colors,\n",
    "                          **clustermap_kws)\n",
    "\n",
    "    if norm is None:\n",
    "        cbar_labels = [str(b) for b in bounds[:-1]]\n",
    "        cbar_labels[-1] = '>' + cbar_labels[-1]\n",
    "        cg.cax.set_xticklabels(cbar_labels)\n",
    "    cg.ax_heatmap.set_xlabel(r'CDR3$\\beta$ Sequence')\n",
    "    cg.ax_heatmap.set_ylabel(r'CDR3$\\beta$ Sequence')\n",
    "\n",
    "    cg.ax_heatmap.text(len(df)*0.6,len(df)*0.15,f'{epitope_name}', fontsize=12,color='white')\n",
    "    cg.ax_heatmap.text(len(df)*0.63,len(df)*0.23,f'threshold: {dist_thres}', fontsize=10,color='white')\n",
    "    cg.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "    return distances, cg, linkage, cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d4ea3",
   "metadata": {},
   "source": [
    "## Probability matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ff9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_count(sequences, \n",
    "              default_pseudocount = 0.2,\n",
    "              states_alph = [\"-\",\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"Y\"]\n",
    "             ):\n",
    "    \"\"\"\n",
    "    Creates frequency/probability matrix of AAs at each position from a set of sequences.\n",
    "    Includes a frequency pseudocount set by 'default_pseudocount'.\n",
    "    \"\"\"\n",
    "    data = {'Seqs': sequences}\n",
    "    df = pd.DataFrame(data, columns = ['Seqs'])\n",
    "\n",
    "    freq_df = (df.Seqs.apply(list).apply(pd.Series).apply(pd.value_counts))\n",
    "    \n",
    "    present_letters = list(freq_df.index.values)\n",
    "    \n",
    "    # amino acids not present in a chain \n",
    "    absent_letters = []    \n",
    "    for char in states_alph:\n",
    "        if char not in present_letters:\n",
    "            absent_letters.append(char)\n",
    "\n",
    "    for i in absent_letters:\n",
    "        freq_df =  freq_df.reindex(states_alph)\n",
    "       \n",
    "    new_freq_df = freq_df.fillna(0) \n",
    "    new_freq_df += default_pseudocount #add pseudocount to all positions\n",
    "    \n",
    "    prob_df = new_freq_df.apply(lambda x: x.div(x.sum()))\n",
    "\n",
    "    return new_freq_df, prob_df\n",
    "\n",
    "def clusters_prob_mat(clustered_seqs, alignment = 'Glob lalg', default_pseudocount = 0.2):\n",
    "    \"\"\"\n",
    "    Creates a dictionary of probability matrices for each cluster in clustered_seqs.\n",
    "    \n",
    "    \"\"\"\n",
    "    prob_mats = {}\n",
    "    \n",
    "    for n in range(len(clustered_seqs.keys())):\n",
    "        \n",
    "        seqs = clustered_seqs[f'Group {n}'][alignment]\n",
    "        train_freq,train_prob = pos_count(seqs, default_pseudocount = default_pseudocount)\n",
    "\n",
    "        prob_mats[f\"Group {n}\"] = {}\n",
    "        prob_mats[f\"Group {n}\"] = train_prob\n",
    "\n",
    "    return (prob_mats)\n",
    "\n",
    "def make_probability_dict(variables, lDict,rDict, \n",
    "                          epitope_names = ['YLQPRTFLL','GILGFVFTL'], var_name = 'Threshold',\n",
    "                          default_pseudocount = 0.2, default_threshold = 7):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a dictionary of probability matrices of all clusters in lDict and rDict.\n",
    "    Inputs:\n",
    "        - variables: list of variables (e.g. threshold, pseudocounts)\n",
    "    \"\"\"\n",
    "    \n",
    "    lprob_Dict = {}\n",
    "    rprob_Dict = {}\n",
    "    \n",
    "    if var_name == 'Threshold': \n",
    "\n",
    "        for t in variables:\n",
    "            lprob_Dict[f\"Threshold {t}\"] = {}\n",
    "            rprob_Dict[f\"Threshold {t}\"] = {}\n",
    "\n",
    "            for ep in epitope_names:\n",
    "                lalg, ralg = lDict[f'Threshold {t}'][ep], rDict[f'Threshold {t}'][ep]\n",
    "\n",
    "                lprob_Dict[f\"Threshold {t}\"][ep] = {}\n",
    "                rprob_Dict[f\"Threshold {t}\"][ep] = {}\n",
    "\n",
    "                lprob_mat = clusters_prob_mat(clustered_seqs = lalg, alignment = 'Glob lalg', default_pseudocount = default_pseudocount)\n",
    "                rprob_mat = clusters_prob_mat(clustered_seqs = ralg, alignment = 'Glob ralg', default_pseudocount = default_pseudocount)\n",
    "\n",
    "                lprob_Dict[f\"Threshold {t}\"][ep] = lprob_mat\n",
    "                rprob_Dict[f\"Threshold {t}\"][ep] = rprob_mat\n",
    "                \n",
    "    if var_name == 'Pseudocount': \n",
    "\n",
    "        for pc in variables:\n",
    "            lprob_Dict[f\"Pseudocount {pc}\"] = {}\n",
    "            rprob_Dict[f\"Pseudocount {pc}\"] = {}\n",
    "\n",
    "            for ep in epitope_names:\n",
    "                lalg, ralg = lDict[f'Threshold {default_threshold}'][ep], rDict[f'Threshold {default_threshold}'][ep]\n",
    "\n",
    "                lprob_Dict[f\"Pseudocount {pc}\"][ep] = {}\n",
    "                rprob_Dict[f\"Pseudocount {pc}\"][ep] = {}\n",
    "\n",
    "                lprob_mat = clusters_prob_mat(clustered_seqs = lalg, alignment = 'Glob lalg', default_pseudocount = pc)\n",
    "                rprob_mat = clusters_prob_mat(clustered_seqs = ralg, alignment = 'Glob ralg', default_pseudocount = pc)\n",
    "\n",
    "                lprob_Dict[f\"Pseudocount {pc}\"][ep] = lprob_mat\n",
    "                rprob_Dict[f\"Pseudocount {pc}\"][ep] = rprob_mat\n",
    "\n",
    "            \n",
    "    return(lprob_Dict, rprob_Dict)\n",
    "\n",
    "\n",
    "def seq_prob(seq_prob, test_seq):\n",
    "    \"\"\"\n",
    "    Probability of a sequence (test_seq) given \n",
    "    probability matrix (seq_prob) from training sequences\n",
    "    \"\"\"\n",
    "    probs = []\n",
    "    for i, AA in enumerate(test_seq):\n",
    "        AA_prob = seq_prob.loc[AA,i]\n",
    "        probs.append(AA_prob)\n",
    "    all_prob = np.prod(probs) # overall prob is the products of each AA in each pos.\n",
    "    return all_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb4736",
   "metadata": {},
   "source": [
    "## Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eddc16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(variable, test_seqs, \n",
    "             lprobs, rprobs, ep1_name = 'YLQPRTFLL',ep2_name ='GILGFVFTL',\n",
    "             var_name = 'Threshold',\n",
    "             default_pseudocount = 0.2, default_threshold = 7):\n",
    "    \"\"\"\n",
    "    Predicts the epitope specificity of each sequence in test_seqs based on the maximum\n",
    "    probability from all clusters from each epitope. \n",
    "        - variable: value of variable being tested (t,pseudocount)\n",
    "        - lprobs: dict of left padded probability matrices.\n",
    "        - rprobs: dict of right padded probability matrices\n",
    "        \n",
    "    Returns the accuracies of the left/right padded sequences \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lcorrect_count,rcorrect_count = 0,0\n",
    "    lclustersizes1,rclustersizes1,lclustersizes2,rclustersizes2 = ([] for i in range(4))    \n",
    "    \n",
    "    if var_name == 'Threshold': \n",
    "        lprob_dict = lprobs[f'Threshold {variable}']\n",
    "        rprob_dict = rprobs[f'Threshold {variable}']\n",
    "        \n",
    "    elif var_name == 'Pseudocount':\n",
    "        lprob_dict = lprobs[f'Pseudocount {variable}']\n",
    "        rprob_dict = rprobs[f'Pseudocount {variable}']\n",
    "        \n",
    "    number_of_groups_ep1= min( len(lprob_dict[ep1_name]) , len(rprob_dict[ep1_name]) )\n",
    "    number_of_groups_ep2= min( len(lprob_dict[ep2_name]) , len(rprob_dict[ep2_name]) )\n",
    "\n",
    "    for k in range(len(test_seqs.index)):\n",
    "\n",
    "        true_ep = test_seqs.iloc[k]['Epitope']\n",
    "        \n",
    "        # left/right padded test sequence\n",
    "        l_test = test_seqs['Glob lalg'][k]\n",
    "        r_test = test_seqs['Glob ralg'][k]\n",
    "\n",
    "        print(f\"Seq {k} ({true_ep}): lalg = {l_test}, ralg = {r_test}\")\n",
    "        \n",
    "        lmin_prob1, rmin_prob1, lmin_prob2, rmin_prob2 = 0,0,0,0\n",
    "        lprobs1, rprobs1, lprobs2, rprobs2 =[],[],[],[]\n",
    "\n",
    "        # EPITOPE 1\n",
    "        for n in range(number_of_groups_ep1):\n",
    "            lprob_mat1 = lprob_dict[ep1_name][f'Group {n}']\n",
    "            lseq_probs1 = seq_prob(lprob_mat1,l_test)\n",
    "            lprobs1.append(lseq_probs1)\n",
    "\n",
    "            if lmin_prob1<lseq_probs1:\n",
    "                lmin_prob1 = lseq_probs1\n",
    "                lmaxgroup1 = (f'Group {n}')\n",
    "\n",
    "            rprob_mat1 = rprob_dict[ep1_name][f'Group {n}']\n",
    "            rseq_probs1 = seq_prob(rprob_mat1,r_test)\n",
    "            rprobs1.append(rseq_probs1)\n",
    "\n",
    "            if rmin_prob1<rseq_probs1:\n",
    "                rmin_prob1 = rseq_probs1\n",
    "                rmaxgroup1 = (f'Group {n}')\n",
    "\n",
    "        lmax_prob_1 = max(lprobs1)\n",
    "        rmax_prob_1 = max(rprobs1)\n",
    "\n",
    "        if var_name == 'Threshold': \n",
    "            lclustersize1 = len(lalg_Dict[f'Threshold {variable}'][ep1_name][lmaxgroup1])\n",
    "            rclustersize1 = len(ralg_Dict[f'Threshold {variable}'][ep1_name][rmaxgroup1])\n",
    "\n",
    "        elif var_name == 'Pseudocount': \n",
    "            lclustersize1 = len(lalg_Dict[f'Threshold {default_threshold}'][ep1_name][lmaxgroup1])\n",
    "            rclustersize1 = len(ralg_Dict[f'Threshold {default_threshold}'][ep1_name][rmaxgroup1])\n",
    "            \n",
    "        lclustersizes1.append(lclustersize1)\n",
    "        rclustersizes1.append(rclustersize1)\n",
    "        print(f\"{ep1_name:.3}: (left) max prob = {lmax_prob_1:.3} from {lmaxgroup1} ({lclustersize1} seqs), \\t(right) max prob = {rmax_prob_1:.3} from {rmaxgroup1} ({rclustersize1} seqs)\")\n",
    "\n",
    "        # EPITOPE 2\n",
    "        for m in range(number_of_groups_ep2):\n",
    "\n",
    "            lprob_mat2 = lprob_dict[ep2_name][f'Group {m}']\n",
    "            lseq_probs2 = seq_prob(lprob_mat2,l_test)\n",
    "            lprobs2.append(lseq_probs2)\n",
    "\n",
    "            if lmin_prob2<lseq_probs2:\n",
    "                lmin_prob2 = lseq_probs2\n",
    "                lmaxgroup2 = (f'Group {m}')\n",
    "\n",
    "            rprob_mat2 = rprob_dict[ep2_name][f'Group {m}']\n",
    "            rseq_probs2 = seq_prob(rprob_mat2,r_test)\n",
    "            rprobs2.append(rseq_probs2)\n",
    "\n",
    "            if rmin_prob2<rseq_probs2:\n",
    "                rmin_prob2 = rseq_probs2\n",
    "                rmaxgroup2 = (f'Group {m}')      \n",
    "\n",
    "    \n",
    "        lmax_prob_2 = max(lprobs2)\n",
    "        rmax_prob_2 = max(rprobs2)\n",
    "        \n",
    "        if var_name == 'Threshold': \n",
    "            lclustersize2 = len(lalg_Dict[f'Threshold {variable}'][ep2_name][lmaxgroup2])\n",
    "            rclustersize2 = len(ralg_Dict[f'Threshold {variable}'][ep2_name][rmaxgroup2])\n",
    "\n",
    "        elif var_name == 'Pseudocount': \n",
    "            lclustersize2 = len(lalg_Dict[f'Threshold {default_threshold}'][ep2_name][lmaxgroup2])\n",
    "            rclustersize2 = len(ralg_Dict[f'Threshold {default_threshold}'][ep2_name][rmaxgroup2])\n",
    "        \n",
    "        lclustersizes2.append(lclustersize2)\n",
    "        rclustersizes2.append(rclustersize2)\n",
    "        \n",
    "        print(f\"{ep2_name:.3}: (left) max prob = {lmax_prob_2:.3} from {lmaxgroup2} ({lclustersize2} seqs), \\t(right) max prob = {rmax_prob_2:.3} from {rmaxgroup2} ({rclustersize2} seqs)\")\n",
    "\n",
    "        epitope_names = [ep1_name, ep2_name]\n",
    "        \n",
    "        if lmax_prob_1>lmax_prob_2: \n",
    "            lpred_epitope = ep1_name\n",
    "        elif lmax_prob_1<lmax_prob_2:\n",
    "            lpred_epitope = ep2_name\n",
    "        else: lpred_epitope = random.choice(epitope_names)\n",
    "            \n",
    "        if rmax_prob_1>rmax_prob_2: \n",
    "            rpred_epitope = ep1_name\n",
    "        elif rmax_prob_1<rmax_prob_2:\n",
    "            rpred_epitope = ep2_name\n",
    "        else: rpred_epitope = random.choice(epitope_names) # randomly choose if probs are equal\n",
    "\n",
    "        print(\"(L) Predicted:\", lpred_epitope, \"\\t(R) Predicted:\", rpred_epitope)\n",
    "        print()\n",
    "\n",
    "        if lpred_epitope == true_ep: lcorrect_count+=1\n",
    "  \n",
    "        if rpred_epitope == true_ep: rcorrect_count+=1\n",
    "\n",
    "    left_accuracy = lcorrect_count/len(test_seqs.index) \n",
    "    right_accuracy = rcorrect_count/len(test_seqs.index) \n",
    "\n",
    "    print(f\"L_acc = {left_accuracy}, R_acc = {right_accuracy}\")   \n",
    "    print()\n",
    "\n",
    "    \n",
    "    return (lclustersizes1,rclustersizes1,lclustersizes2,rclustersizes2, left_accuracy, right_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e44355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061e96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
